{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFNCK4Ico-Pe"
      },
      "source": [
        "**Efficient Fine-Tuning of LLaMA 3.1 8B-Instruct with 4-bit Quantization and LoRA**\n",
        "\n",
        "This project demonstrates the efficient deployment and fine-tuning of the LLaMA 3.1 8B-Instruct model using 4-bit quantization (via bitsandbytes) and Low-Rank Adaptation (LoRA) for memory-efficient adaptation of large-scale language models. The aim is to make large transformer-based models accessible and tunable even on modest hardware setups.\n",
        "\n",
        "Objective:\n",
        "To load and fine-tune a quantized LLaMA 3.1 (8B) model using 4-bit quantization and LoRA adapters, thereby reducing GPU memory requirements and accelerating training while preserving performance.\n",
        "\n",
        "Key Technologies:\n",
        "BitsAndBytes 4-bit Quantization: Reduces memory usage and speeds up inference by representing weights with only 4 bits and computing with 16-bit precision (float16).\n",
        "\n",
        "LoRA (Low-Rank Adaptation): Fine-tunes small adapter layers inserted into the frozen base model, significantly reducing the number of trainable parameters.\n",
        "\n",
        "Transformers and Accelerate Libraries: Power seamless model loading, tokenization, and training workflows.\n",
        "\n",
        "Model & Tokenizer:\n",
        "Base Model: LLaMA 3.1 - 8B Instruct\n",
        "\n",
        "Tokenizer is loaded with padding set to eos_token for causal language modeling compatibility.\n",
        "\n",
        "Quantization is configured with load_in_4bit=True and bnb_4bit_compute_dtype='float16'.\n",
        "\n",
        "Training Strategy:\n",
        "The model is trained using Hugging Face's Trainer API.\n",
        "\n",
        "LoRA adapters are injected into the base model to fine-tune it on a custom dataset while keeping the majority of model weights frozen.\n",
        "\n",
        "Only a small fraction of parameters are updated, greatly reducing computational cost.\n",
        "\n",
        "Benefits:\n",
        "High Efficiency: By combining LoRA and 4-bit quantization, this setup achieves a strong trade-off between performance and memory usage.\n",
        "\n",
        "Scalability: Enables experimentation with multi-billion parameter models on single or few-GPU environments.\n",
        "\n",
        "Customization: The architecture supports domain adaptation, dialogue fine-tuning, or specialized instruction following with minimal resources.\n",
        "\n",
        "This project exemplifies modern strategies to scale down large language model usage and training, democratizing access to powerful AI tools for research, prototyping, and deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-02-16T07:42:34.708309Z",
          "iopub.status.busy": "2025-02-16T07:42:34.708044Z",
          "iopub.status.idle": "2025-02-16T07:42:35.531848Z",
          "shell.execute_reply": "2025-02-16T07:42:35.531127Z",
          "shell.execute_reply.started": "2025-02-16T07:42:34.708276Z"
        },
        "trusted": true,
        "id": "XvP9IsRuo-Pi"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:42:35.533265Z",
          "iopub.status.busy": "2025-02-16T07:42:35.532846Z",
          "iopub.status.idle": "2025-02-16T07:42:44.050523Z",
          "shell.execute_reply": "2025-02-16T07:42:44.049444Z",
          "shell.execute_reply.started": "2025-02-16T07:42:35.533242Z"
        },
        "trusted": true,
        "id": "DtdhX4n9o-Pk"
      },
      "outputs": [],
      "source": [
        "# Installing bitsandbytes for quantization\n",
        "!pip uninstall -y bitsandbytes\n",
        "!pip install -U bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:42:44.051877Z",
          "iopub.status.busy": "2025-02-16T07:42:44.051561Z",
          "iopub.status.idle": "2025-02-16T07:42:48.072653Z",
          "shell.execute_reply": "2025-02-16T07:42:48.071791Z",
          "shell.execute_reply.started": "2025-02-16T07:42:44.051848Z"
        },
        "trusted": true,
        "id": "1Jumj5fOo-Pk"
      },
      "outputs": [],
      "source": [
        "#Important libraries\n",
        "import importlib\n",
        "import torch\n",
        "import bitsandbytes as bnb\n",
        "importlib.reload(bnb)\n",
        "print(\"bitsandbytes version:\", bnb.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:42:48.075127Z",
          "iopub.status.busy": "2025-02-16T07:42:48.074693Z",
          "iopub.status.idle": "2025-02-16T07:42:48.078863Z",
          "shell.execute_reply": "2025-02-16T07:42:48.078145Z",
          "shell.execute_reply.started": "2025-02-16T07:42:48.075092Z"
        },
        "trusted": true,
        "id": "qpJ9vqJPo-Pk"
      },
      "outputs": [],
      "source": [
        "torch.cuda.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:42:48.080732Z",
          "iopub.status.busy": "2025-02-16T07:42:48.080517Z",
          "iopub.status.idle": "2025-02-16T07:43:00.699516Z",
          "shell.execute_reply": "2025-02-16T07:43:00.698793Z",
          "shell.execute_reply.started": "2025-02-16T07:42:48.080708Z"
        },
        "trusted": true,
        "id": "mMqi72Rwo-Pl"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers\n",
        "\n",
        "import transformers\n",
        "\n",
        "#To enable efficient memory handling\n",
        "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
        "torch.backends.cuda.enable_flash_sdp(False)\n",
        "\n",
        "model_path= \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:43:00.700697Z",
          "iopub.status.busy": "2025-02-16T07:43:00.700353Z",
          "iopub.status.idle": "2025-02-16T07:43:04.160426Z",
          "shell.execute_reply": "2025-02-16T07:43:04.159484Z",
          "shell.execute_reply.started": "2025-02-16T07:43:00.700675Z"
        },
        "trusted": true,
        "id": "JHGr-0gco-Pl"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:43:04.162022Z",
          "iopub.status.busy": "2025-02-16T07:43:04.161702Z",
          "iopub.status.idle": "2025-02-16T07:43:25.98078Z",
          "shell.execute_reply": "2025-02-16T07:43:25.980082Z",
          "shell.execute_reply.started": "2025-02-16T07:43:04.161992Z"
        },
        "trusted": true,
        "id": "Vu7VBGYbo-Pl"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:43:25.982138Z",
          "iopub.status.busy": "2025-02-16T07:43:25.981571Z",
          "iopub.status.idle": "2025-02-16T07:43:26.247433Z",
          "shell.execute_reply": "2025-02-16T07:43:26.246789Z",
          "shell.execute_reply.started": "2025-02-16T07:43:25.982111Z"
        },
        "trusted": true,
        "id": "9KuXhIsZo-Pl"
      },
      "outputs": [],
      "source": [
        "#Loading the training dataset using datasets\n",
        "train_dataset = load_dataset(\"csv\", data_files='/kaggle/input/multi-lingual-sentiment-analysis/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:43:26.248442Z",
          "iopub.status.busy": "2025-02-16T07:43:26.248197Z",
          "iopub.status.idle": "2025-02-16T07:43:26.327831Z",
          "shell.execute_reply": "2025-02-16T07:43:26.327149Z",
          "shell.execute_reply.started": "2025-02-16T07:43:26.248422Z"
        },
        "trusted": true,
        "id": "c-5rXw2qo-Pm"
      },
      "outputs": [],
      "source": [
        "#Loading test data\n",
        "test_dataset=load_dataset(\"csv\", data_files=\"/kaggle/input/multi-lingual-sentiment-analysis/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:43:26.328984Z",
          "iopub.status.busy": "2025-02-16T07:43:26.328732Z",
          "iopub.status.idle": "2025-02-16T07:43:26.333329Z",
          "shell.execute_reply": "2025-02-16T07:43:26.33235Z",
          "shell.execute_reply.started": "2025-02-16T07:43:26.328963Z"
        },
        "trusted": true,
        "id": "ivhdMbnso-Pm"
      },
      "outputs": [],
      "source": [
        "#Dictionary for language mapping\n",
        "lang={'as': 'Assamese','bd': 'Bodo','bn': 'Bengali','gu': 'Gujarati','hi': 'Hindi','kn': 'Kannada','ml':'Malayalam','mr': 'Marathi','or': 'Odia','pa': 'Punjabi','ta': 'Tamil','te': 'Telugu','ur': 'Urdu'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:43:26.377614Z",
          "iopub.status.busy": "2025-02-16T07:43:26.377423Z",
          "iopub.status.idle": "2025-02-16T07:43:36.862132Z",
          "shell.execute_reply": "2025-02-16T07:43:36.861302Z",
          "shell.execute_reply.started": "2025-02-16T07:43:26.377598Z"
        },
        "trusted": true,
        "id": "M2-ROU6Qo-Pm"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y bitsandbytes\n",
        "!pip install -U bitsandbytes\n",
        "\n",
        "!pip install -U transformers accelerate\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True,  # Enable 4-bit quantization\n",
        "    bnb_4bit_compute_dtype=\"float16\")  # Setting computation precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:43:36.863422Z",
          "iopub.status.busy": "2025-02-16T07:43:36.863109Z",
          "iopub.status.idle": "2025-02-16T07:44:51.670237Z",
          "shell.execute_reply": "2025-02-16T07:44:51.669297Z",
          "shell.execute_reply.started": "2025-02-16T07:43:36.863401Z"
        },
        "trusted": true,
        "id": "MIE1fiiOo-Pn"
      },
      "outputs": [],
      "source": [
        "# Loading the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Loading the model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,pad_token_id=tokenizer.eos_token_id, quantization_config=quantization_config,\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:51.671585Z",
          "iopub.status.busy": "2025-02-16T07:44:51.671255Z",
          "iopub.status.idle": "2025-02-16T07:44:51.675453Z",
          "shell.execute_reply": "2025-02-16T07:44:51.674577Z",
          "shell.execute_reply.started": "2025-02-16T07:44:51.671555Z"
        },
        "trusted": true,
        "id": "s4cy6Puco-Pn"
      },
      "outputs": [],
      "source": [
        "#Dictionary for mapping prompt\n",
        "option={\"Positive\":\"A\",\"Negative\":\"B\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:51.693202Z",
          "iopub.status.busy": "2025-02-16T07:44:51.692968Z",
          "iopub.status.idle": "2025-02-16T07:44:51.709027Z",
          "shell.execute_reply": "2025-02-16T07:44:51.708429Z",
          "shell.execute_reply.started": "2025-02-16T07:44:51.693184Z"
        },
        "trusted": true,
        "id": "QfGO37PPo-Pn"
      },
      "outputs": [],
      "source": [
        "# Function for adding a column in the dataset having the prompt\n",
        "def modify_data(example):\n",
        "    language=lang[example[\"language\"]]\n",
        "    prompt=\"Question: Which sentiment does the sentence \"+ example[\"sentence\"]+ \" in the Indian language \"+language+\" have? Option A) Positive, Option B) Negative.The answer is Option \"+option[example[\"label\"]]+\") \"+example[\"label\"]\n",
        "    example[\"modified_text\"] = prompt\n",
        "    return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:51.710036Z",
          "iopub.status.busy": "2025-02-16T07:44:51.709828Z",
          "iopub.status.idle": "2025-02-16T07:44:51.814164Z",
          "shell.execute_reply": "2025-02-16T07:44:51.813346Z",
          "shell.execute_reply.started": "2025-02-16T07:44:51.710019Z"
        },
        "trusted": true,
        "id": "K7M-Yn7so-Pn"
      },
      "outputs": [],
      "source": [
        "#Modifying the dataset by adding a prompt column\n",
        "train_dataset=train_dataset[\"train\"].map(modify_data,remove_columns=['ID', 'sentence', 'label', 'language'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:51.819101Z",
          "iopub.status.busy": "2025-02-16T07:44:51.818882Z",
          "iopub.status.idle": "2025-02-16T07:44:51.835136Z",
          "shell.execute_reply": "2025-02-16T07:44:51.834473Z",
          "shell.execute_reply.started": "2025-02-16T07:44:51.819055Z"
        },
        "trusted": true,
        "id": "bLsGeqvao-Pn"
      },
      "outputs": [],
      "source": [
        "#Tokenizing function\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"modified_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:51.851399Z",
          "iopub.status.busy": "2025-02-16T07:44:51.851101Z",
          "iopub.status.idle": "2025-02-16T07:44:52.636281Z",
          "shell.execute_reply": "2025-02-16T07:44:52.635436Z",
          "shell.execute_reply.started": "2025-02-16T07:44:51.851371Z"
        },
        "trusted": true,
        "id": "fWAObYCio-Po"
      },
      "outputs": [],
      "source": [
        "train_dataset= train_dataset.map(tokenize,batched=True,num_proc=4, remove_columns=['modified_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:52.642753Z",
          "iopub.status.busy": "2025-02-16T07:44:52.642481Z",
          "iopub.status.idle": "2025-02-16T07:44:52.659904Z",
          "shell.execute_reply": "2025-02-16T07:44:52.659215Z",
          "shell.execute_reply.started": "2025-02-16T07:44:52.642726Z"
        },
        "trusted": true,
        "id": "0k_P3hyJo-Po"
      },
      "outputs": [],
      "source": [
        "#Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer,mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:52.678536Z",
          "iopub.status.busy": "2025-02-16T07:44:52.678259Z",
          "iopub.status.idle": "2025-02-16T07:44:52.690625Z",
          "shell.execute_reply": "2025-02-16T07:44:52.690035Z",
          "shell.execute_reply.started": "2025-02-16T07:44:52.678498Z"
        },
        "trusted": true,
        "id": "OfxFPaFCo-Po"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, TaskType, LoraModel\n",
        "\n",
        "#Lora configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    inference_mode=False,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:52.691791Z",
          "iopub.status.busy": "2025-02-16T07:44:52.691489Z",
          "iopub.status.idle": "2025-02-16T07:44:52.884666Z",
          "shell.execute_reply": "2025-02-16T07:44:52.883936Z",
          "shell.execute_reply.started": "2025-02-16T07:44:52.691762Z"
        },
        "trusted": true,
        "id": "SC0RFLk2o-Po"
      },
      "outputs": [],
      "source": [
        "from peft import get_peft_model\n",
        "\n",
        "lora_model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:52.885876Z",
          "iopub.status.busy": "2025-02-16T07:44:52.885542Z",
          "iopub.status.idle": "2025-02-16T07:44:52.921797Z",
          "shell.execute_reply": "2025-02-16T07:44:52.920851Z",
          "shell.execute_reply.started": "2025-02-16T07:44:52.885848Z"
        },
        "trusted": true,
        "id": "V7Z7wBk6o-Po"
      },
      "outputs": [],
      "source": [
        "#The training arguments\n",
        "training_args = TrainingArguments( output_dir='lora_llama_1b_ct',\n",
        "                                  num_train_epochs=5,\n",
        "                                  per_device_train_batch_size=1,\n",
        "                                  bf16=False,\n",
        "                                  fp16=False,\n",
        "                                  tf32=False,\n",
        "                                  gradient_accumulation_steps=10,\n",
        "                                  adam_beta1=0.9,\n",
        "                                  adam_beta2=0.999,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  weight_decay=0.01,\n",
        "                                  logging_dir='logs',\n",
        "                                  report_to='none',\n",
        "                                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:52.922944Z",
          "iopub.status.busy": "2025-02-16T07:44:52.922617Z",
          "iopub.status.idle": "2025-02-16T07:44:52.944175Z",
          "shell.execute_reply": "2025-02-16T07:44:52.943554Z",
          "shell.execute_reply.started": "2025-02-16T07:44:52.922923Z"
        },
        "trusted": true,
        "id": "UX9bs--oo-Po"
      },
      "outputs": [],
      "source": [
        "#Creating the trainer\n",
        "trainer = Trainer(model=lora_model,\n",
        "                  args = training_args,\n",
        "                 train_dataset=train_dataset,\n",
        "                 eval_dataset=None,\n",
        "                 data_collator = data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T07:44:52.945342Z",
          "iopub.status.busy": "2025-02-16T07:44:52.94504Z",
          "iopub.status.idle": "2025-02-16T07:56:27.126538Z",
          "shell.execute_reply": "2025-02-16T07:56:27.12527Z",
          "shell.execute_reply.started": "2025-02-16T07:44:52.945314Z"
        },
        "trusted": true,
        "id": "FdkrMInCo-Pp"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "results = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T08:19:01.443512Z",
          "iopub.status.busy": "2025-02-16T08:19:01.443191Z",
          "iopub.status.idle": "2025-02-16T08:19:01.447465Z",
          "shell.execute_reply": "2025-02-16T08:19:01.446582Z",
          "shell.execute_reply.started": "2025-02-16T08:19:01.44349Z"
        },
        "trusted": true,
        "id": "elNvaac7o-Pp"
      },
      "outputs": [],
      "source": [
        "#Lists to add the predictions and indices\n",
        "predictions=[]\n",
        "ids=[]\n",
        "id=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T08:19:03.027744Z",
          "iopub.status.busy": "2025-02-16T08:19:03.027455Z",
          "iopub.status.idle": "2025-02-16T08:20:50.954426Z",
          "shell.execute_reply": "2025-02-16T08:20:50.953675Z",
          "shell.execute_reply.started": "2025-02-16T08:19:03.027722Z"
        },
        "trusted": true,
        "id": "sN0-W_eSo-Pp"
      },
      "outputs": [],
      "source": [
        "for data in test_dataset[\"train\"]:\n",
        "    language=lang[data[\"language\"]]\n",
        "\n",
        "    #Creating prompt\n",
        "    prompt=\"Question: Which sentiment does the sentence \"+ data[\"sentence\"]+ \" in the Indian language \"+language+\" have? Option A) Positive, Option B) Negative.The answer is Option \"\n",
        "    len_prompt=len(prompt)\n",
        "    #Tokenized inputs\n",
        "    inputs = tokenizer(prompt,return_tensors='pt')\n",
        "    #Generating output\n",
        "    outputs = lora_model.generate(**inputs, max_new_tokens=10, do_sample=False)\n",
        "    output=tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    stringout=output[0][len_prompt:]\n",
        "    stringout=stringout.lower()\n",
        "    #Checking if the CLM output contains the words Positive or Negative\n",
        "    if \"positive\" in stringout[:15]:\n",
        "        predictions.append(\"Positive\")\n",
        "    else:\n",
        "        predictions.append(\"Negative\")\n",
        "    ids.append(id)\n",
        "    id+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-16T08:20:58.350105Z",
          "iopub.status.busy": "2025-02-16T08:20:58.349685Z",
          "iopub.status.idle": "2025-02-16T08:20:58.367519Z",
          "shell.execute_reply": "2025-02-16T08:20:58.366678Z",
          "shell.execute_reply.started": "2025-02-16T08:20:58.350057Z"
        },
        "trusted": true,
        "id": "8_YM0iwpo-Pp"
      },
      "outputs": [],
      "source": [
        "#Converting to csv\n",
        "submission = pd.DataFrame({\n",
        "    'ID': ids,                # ID column\n",
        "    'label':predictions  # Predictions column\n",
        "})\n",
        "\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 11098970,
          "sourceId": 93282,
          "sourceType": "competition"
        },
        {
          "modelId": 91102,
          "modelInstanceId": 68809,
          "sourceId": 104449,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}